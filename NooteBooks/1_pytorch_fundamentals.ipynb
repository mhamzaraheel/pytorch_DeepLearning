{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
      "colab_type": "text",
      "id": "view-in-github"
       },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhamzaraheel/pytorch_DeepLearning/blob/main/NooteBooks/1_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLFCC7z3BOij"
      },
      "source": [
        "# Pytorch Fundamentals\n",
        "\n",
        "\n",
        "\n",
        "## What is PyTorch?\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is an open source machine learning and deep learning framework taht provides a flexible and dynamic computational graph, which is particularly well-suited for deep learning tasks.\n",
        "\n",
        "\n",
        "## Organizations make use of PyTorch?\n",
        "\n",
        "- Widely adopted by major technology companies including [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla, and Microsoft, as well as prominent AI research institutions like [OpenAI](https://openai.com/blog/openai-pytorch/) plays a crucial role in driving research initiatives and integrating machine learning capabilities into various products.\n",
        "\n",
        "- Andrej Karpathy (head of AI at Tesla) has given several talks ([PyTorch at Tesla](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) about how Tesla use PyTorch to power their self-driving computer vision models.\n",
        "\n",
        "- PyTorch is also used in other industries such as agriculture to [power computer vision on tractors](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
        "\n",
        "## Why use PyTorch?\n",
        "\n",
        "Machine learning researchers love using PyTorch. And as of September 2023, PyTorch is the [most used deep learning framework on Papers With Code](https://paperswithcode.com/trends), a website for tracking machine learning research papers and the code repositories attached with them.\n",
        "\n",
        "PyTorch also helps take care of many things such as GPU acceleration (making your code run faster) behind the scenes.\n",
        "\n",
        "So you can focus on manipulating data and writing algorithms and PyTorch will make sure it runs fast.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MaHVkhiFBHz8",
        "outputId": "f102c6f9-24df-463c-cd97-da7f793b9b7a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.0+cu118'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8hnHJZ1BHuy"
      },
      "source": [
        "## 1.Introduction to tensors\n",
        "\n",
        "\n",
        "Tensors are the fundamental building block of machine learning.\n",
        "\n",
        "Their job is to represent data in a numerical way.\n",
        "\n",
        "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n",
        "\n",
        "\n",
        "![First_Image](https://github.com/mhamzaraheel/pytorch_DeepLearning/blob/main/Images/1%23tensor-shape-example-of-image.png?raw=true)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtZ2oBBB92Xp"
      },
      "source": [
        "### 1.1 Creating Tensor\n",
        "PyTorch has such a strong affinity for tensors that an entire documentation page is devoted to the [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjBCGwBsOnXH"
      },
      "source": [
        "> The first one  is **scalar**.                                                                   \n",
        "                                                                               A scalar is a single number and in  it's a zero dimension tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvgEHYOzBHsM",
        "outputId": "60d9d963-d31b-448e-c8c9-eba6aa543426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Scaler\n",
        "scaler = torch.tensor(5)\n",
        "scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ETyHoKQ4OR"
      },
      "source": [
        "This is how we can get the item (integer) of scaler tensor - `torch.item()`\n",
        "\n",
        "**Note** Only work with one elemnt tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeGc3Ub6C_vY",
        "outputId": "0df1f492-bef9-4c62-d74d-1e28cb743455"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the item of tensor\n",
        "scaler.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v47ExW-kQ_1Z"
      },
      "source": [
        "We can also check the dimension of tesnor using `ndim` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDeY_IjGDQVM",
        "outputId": "f73e4c81-6d91-4d7e-cfc6-44acef185ce1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dimension of the sacler tensor\n",
        "scaler.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg8N_SvdYfcp"
      },
      "source": [
        "Another important concept for tensors is their `shape` attribute. The shape tells you how the elements inside them are arranged.\n",
        "\n",
        "**Note** scaler have no shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAMVpLOpDW4T",
        "outputId": "9b20705d-5b22-43a8-b729-bd8c9969f1d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the scaler tensor (scaler has no shape)\n",
        "scaler.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpvnXxDiSMAj"
      },
      "source": [
        "> The second one is  **vector**.                                                \n",
        "  A vector is a single dimension tensor but can contain many numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPuU2dbnEIxj",
        "outputId": "1825b87a-d562-45f7-9257-6171fe38563b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vector\n",
        "vector = torch.tensor([1,2])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESNuYc18F9uV",
        "outputId": "36407c8c-9f10-4785-baa7-538b71160883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Item =  tensor(1)\n",
            "Second Item =  tensor(2)\n"
          ]
        }
      ],
      "source": [
        "# getting the item of the vector tensor\n",
        "print(\"First Item = \",vector[0])\n",
        "print(\"Second Item = \",vector[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pK3H0RiEWEw",
        "outputId": "2106d5c2-3b08-4927-9ca0-b68d12ce444d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dimension of the vector tensor\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R7kID7uEfD2",
        "outputId": "8dab071b-4f50-4e4e-ad3c-41b7cd3bde5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the vector tensor\n",
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4v0EYRBSrN2"
      },
      "source": [
        "> Now we wil create the  **MATRIX**.                                       \n",
        "  MATRIX same as Vecotr but get a extra dimension.   \n",
        "  MATRIX has two dimension (2d)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwrrE7RAFPs3",
        "outputId": "ea6e54aa-e7f4-4217-c32f-02acd0355a38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[1,2],\n",
        "                       [3,4],\n",
        "                       [5,6]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f5hpKQMGSXu",
        "outputId": "fe17fcc2-4fc8-4953-e630-dccab656ac60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2]), tensor([3, 4]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX[0],MATRIX[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swNjF5g7FkhK",
        "outputId": "14bad477-a6e4-463b-9819-d5d588ffe368"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dimension of the MATRIX tensor\n",
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dFEKVTRFxpe",
        "outputId": "f775b984-5605-447b-bfc4-d7f31e528fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the MATRIX Tensor\n",
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3tZd5AETqTA"
      },
      "source": [
        "> Now what about the **TESNOR** ?                                          \n",
        "  TENSOR can be of multiple dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow9oOvZUF4wu",
        "outputId": "ee3f7073-f9f5-4cd7-9f24-3b34ba697c8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2],\n",
              "         [3, 4],\n",
              "         [5, 6]]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TENSOR\n",
        "TENSOR = torch.tensor([[[1,2],\n",
        "                        [3,4],\n",
        "                        [5,6]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzDU3mOIG2yW",
        "outputId": "af853b11-c95e-4db3-d810-ecd8e90e7ebe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dimension of the TENSOR\n",
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsJcoGbvHDFa",
        "outputId": "c44e8eb7-b80d-41a6-bd34-2d1db1aea464"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 2])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the TENSOR\n",
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD6AmGKiMBMV",
        "outputId": "84b23a4b-5b28-49b0-eef3-e2c7bcc655cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agaw5ODu4ByS"
      },
      "source": [
        "Here below is the Represenatiom of the dimensions.\n",
        "\n",
        "![second_Image](https://github.com/mhamzaraheel/pytorch_DeepLearning/blob/main/Images/1%23-pytorch-different-tensor-dimensions.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwq9OCROY4BB"
      },
      "source": [
        "Let's summarise.\n",
        "\n",
        "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 | Lower (`a`) |\n",
        "| **vector** | a number with direction | 1 | Lower (`y`) |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) |\n",
        "\n",
        "![Third_Image](https://github.com/mhamzaraheel/pytorch_DeepLearning/blob/main/Images/1%23-scalar-vector-matrix-tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Nq1l1EMNJt"
      },
      "source": [
        "### 1.2 Random Tensors\n",
        "\n",
        "Above we have created the Tensors (for the representation of data) by hand, but in machine learning we dont need to create the tensor by hand.\n",
        "\n",
        "Instead Neural Network learn in the way they start with the random numbers `weights and bias` and then start fitting te those random numbers to better representation of the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
        "\n",
        "How can we create the tensors of random numbers?\n",
        "\n",
        "Lets create with [`torch.rand()`]( https://pytorch.org/docs/stable/generated/torch.rand.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBsjad7bMx1e",
        "outputId": "dd61f8fc-6349-4df5-a472-04f1b079c2a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0904, 0.3509, 0.7293],\n",
              "        [0.3561, 0.0027, 0.0671]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a random tensor interval[0,1] of size(2,3)\n",
        "random_tensor = torch.rand(2,3)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPyFotNUbZJ9"
      },
      "source": [
        "We can create the tensor of different shape by adjusting the `size` parameter\n",
        "\n",
        "For example, we can create the tensor of common image shape of `[28, 28, 3]` (`[height, width, color_channels`])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_ojrAlaSbCg",
        "outputId": "bb6590eb-ac63-4a6f-ec47-c3b26b9c7e64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 28, 28]), 3)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create random tensor like a image\n",
        "random_image_tensor = torch.rand(size = (3,28,28))\n",
        "random_image_tensor.shape , random_image_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXbjE7khTVaB"
      },
      "source": [
        "### 1.3 zeros & ones\n",
        "\n",
        "Let's create a tensor full of zeros with [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
        "\n",
        "Let's create a tensor full of ones with [`torch.ones()`](https://pytorch.org/docs/stable/generated/torch.ones.html#torch.ones)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv72AqHGTt75",
        "outputId": "b3e83547-5df3-4702-a0eb-c9eedf578247"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor of all zeros\n",
        "zeros   = torch.zeros(2,2)\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cqXbNieTt4j",
        "outputId": "15666cfd-1b6f-4a25-c95f-565068c25b7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor of all oes\n",
        "ones   = torch.ones(2,2)\n",
        "ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzhly9G0WmqK"
      },
      "source": [
        "### 1.4 zeroslike & oneslike\n",
        "\n",
        "We can create tensor of all zeros with the same shape as a XYZ tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Vcx_kzYAbi",
        "outputId": "d0fdbc1c-ebfb-42cb-9bd9-560824f91628"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-8.7096e-03,  3.2293e-41, -1.0888e-02,  3.2293e-41,  0.0000e+00],\n",
              "        [ 1.8750e+00,  0.0000e+00,  1.8750e+00,  0.0000e+00,  0.0000e+00]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a uninitialized  tensor\n",
        "empty = torch.empty(2,5)\n",
        "empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NykipsepYATp",
        "outputId": "b61a5b03-0322-45e3-90ea-1a360bb94367"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of all zeros same like empty tensor\n",
        "ten_zeros = torch.zeros_like(empty)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRYCKXHTZZej",
        "outputId": "67362c72-df57-4be7-9a9b-96e75e218602"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of all ones same like empty tensor\n",
        "ten_ones = torch.ones_like(empty)\n",
        "ten_ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11EoGDrTt2B"
      },
      "source": [
        "### 1.5 range and arrange\n",
        "\n",
        "\n",
        "We may need to create the tensor of some numbers bw the range , such as 1 to 10 or 0 to 100.\n",
        "\n",
        "You can use [`torch.arange(start, end, step)`](https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange) to do so.\n",
        "\n",
        "Where:\n",
        "* `start` = start of range (e.g. 0)\n",
        "* `end` = end of range (e.g. 10)\n",
        "* `step` = how many steps in between each value (e.g. 1)\n",
        "\n",
        "> **Note:** In Python, you can use `range()` to create a range. However in PyTorch, [`torch.range()`](https://pytorch.org/docs/stable/generated/torch.range.html#torch.range)` is deprecated and may show an error in the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emBhScl_V9-0",
        "outputId": "0f32044b-effc-458c-9c2c-9b5cfc03ede2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-25-61dc7f33f4f9>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  one_to_ten = torch.range(start = 1 , end = 10 , step = 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of range (from 1 to 9)\n",
        "one_to_ten = torch.range(start = 1 , end = 10 , step = 1)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZDEuCxRaNuG",
        "outputId": "bf79eb8d-26db-4ad0-a4de-a53561675ace"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of range (from 1 to 9)\n",
        "one_to_ten = torch.arange(start = 1 , end = 10 , step = 1)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsLs0niPbCOW"
      },
      "source": [
        "### 1.6 Randoom Permutation\n",
        "\n",
        "We can also create the tensor of random permutation of integers from 0 to n - 1\n",
        "\n",
        "For this use the [`torc.randperm()`](https://pytorch.org/docs/stable/generated/torch.randperm.html#torch.randperm)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmWA5fI6biM0",
        "outputId": "b59eccdd-8caa-4fd7-f5b2-d8ff4c9ece7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 2, 3, 1, 4])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of random permutation of integers from 0 to n - 1.\n",
        "\n",
        "random_perm = torch.randperm(5)\n",
        "random_perm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33E7llRvb5Rk"
      },
      "source": [
        "### 1.6 Random Integers\n",
        "\n",
        "\n",
        "[`torch.randint`](https://pytorch.org/docs/stable/generated/torch.randint.html#torch.randint) generates random integers between the [low,high] of specified size .\n",
        "\n",
        "`low` : The lower bound.\n",
        "\n",
        "`high` :The upper bound.\n",
        "\n",
        "`size` : The shape of the output tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D0m7xwRcSwK",
        "outputId": "c6db70fa-ac2b-4cc1-a488-3fe92625dca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 4, 4])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of integer  interval[3,5] of size(3)\n",
        "torch.randint(3, 5, (3,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vse8UazvcfXu",
        "outputId": "29f789f3-4a03-4af6-81de-daee2c2d9528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5, 2],\n",
              "        [0, 7]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of integer  interval[0,8] of size(2,2)\n",
        "torch.randint(8, (2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYYD802ucfVM",
        "outputId": "d14f5f67-d154-4155-8c7c-3bdfc16a358f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[6, 8],\n",
              "        [7, 5]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the tensor of integer  interval[5,10] of size(2,2)\n",
        "torch.randint(5, 10, (2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prMR2No8aTak"
      },
      "source": [
        "### 1.7 Tensor datatypes\n",
        "\n",
        "\n",
        "There are many different [tensor datatypes in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "\n",
        "**Note:** we face many time the following errors\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device\n",
        "\n",
        "> Tensors on which we are performing operations are of same datatye, and on same device .                        \n",
        "  Some operations require the specific shape rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pipdqQ83ar1d",
        "outputId": "9abb008b-89c5-4931-c3d5-019b6d6d0420"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 3., 4.], requires_grad=True)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor = torch.tensor([2.,3.,4.],\n",
        "                               dtype = None, # data type of the tensor\n",
        "                               device = None, # on which device your tensor\n",
        "                               requires_grad = True) # want to track the gradients or not with this tesor operations\n",
        "\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VVLSOL2gBmn",
        "outputId": "817c16b4-3724-401d-a5ad-84860057ffa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSFJjkEhgL62",
        "outputId": "9f5ae3b5-daf2-4943-92be-a1534bddf144"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 3., 4.], dtype=torch.float16, grad_fn=<ToCopyBackward0>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert the data type from float32 to float16\n",
        "float_16_tensor =  float_32_tensor.type(torch.float16)\n",
        "float_16_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iTjnPGqgYvn"
      },
      "source": [
        "## 2.Tensor Information (Tensor Attributes)\n",
        "\n",
        "1. Tensors not right datatype - to do get datatype of a tensor, we can use `tensor.dtype`\n",
        "2. Tensors not right shape - to get shape of a tensor, we can use `tensor.shape`\n",
        "3. Tensors not on the right device - to get device of a tensor,we can use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y41Gq95NjI2R",
        "outputId": "f7c3b7f9-2355-4a6a-dd22-1be1c168fa8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.9570, 0.3697, 0.0180, 0.1580],\n",
              "        [0.3259, 0.2093, 0.1984, 0.1066],\n",
              "        [0.7739, 0.3862, 0.5825, 0.3467]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zVM3w1yjhIO",
        "outputId": "2f7ea20e-0108-4485-896d-fdc7a1856d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datatype of the Tensor: torch.float32\n",
            "Shape of the Tensor: torch.Size([3, 4])\n",
            "Device of the Tensor: cpu \n",
            " \n"
          ]
        }
      ],
      "source": [
        "# gettin infromation of tensor\n",
        "print(f\"\"\"Datatype of the Tensor: {random_tensor.dtype}\n",
        "Shape of the Tensor: {random_tensor.shape}\n",
        "Device of the Tensor: {random_tensor.device} \\n \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS1-_r7-lx9j"
      },
      "source": [
        "## 3.Different Tensor Operations\n",
        "\n",
        "Tensor opertions include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LwRaTgQ0i_x"
      },
      "source": [
        "### 3.1 Basic operations\n",
        "\n",
        "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_b7RiKqmdwF",
        "outputId": "a7b76aa7-3deb-4339-ca81-b34deae7c534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "some_tensor =  torch.tensor([[1,2,3],\n",
        "                          [4,5,6]])\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tcTKdKrmuPJ",
        "outputId": "6aeae06b-dc94-4c88-d76e-72841ae9691e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6,  7,  8],\n",
              "        [ 9, 10, 11]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add 5 to the  every elemnt\n",
        "some_tensor + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj0z-eFanWq3",
        "outputId": "a5acddab-e755-4512-e3e1-1e8a6ff3c581"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6,  7,  8],\n",
              "        [ 9, 10, 11]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Bulit in function\n",
        "torch.add(some_tensor , 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOxTWj1UnLAu",
        "outputId": "e3c2bcf2-8dff-4af7-dd05-2e373ef4c6aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-4, -3, -2],\n",
              "        [-1,  0,  1]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subtract the 5 from every elemnt\n",
        "some_tensor - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRrjn9rOnBPw",
        "outputId": "225b8c85-6e14-48b1-be52-cb4e9ff402d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5, 10, 15],\n",
              "        [20, 25, 30]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply every elemnt with 5\n",
        "some_tensor * 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNVak4binHjQ",
        "outputId": "0fcdccc9-5205-443b-8fd0-ec5f1d7c2ebe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5, 10, 15],\n",
              "        [20, 25, 30]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Bulit in function for multiplication\n",
        "torch.mul(some_tensor,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87-ceSGinqaj"
      },
      "source": [
        "### 3.2 Sum of all the items/elements of tensor\n",
        "\n",
        "**Resource** - Here is [`torch.sum`](https://pytorch.org/docs/stable/generated/torch.sum.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WaknUt1QofUW"
      },
      "outputs": [],
      "source": [
        "# MATRIX (2-dimensional)\n",
        "tensor_2d =torch.tensor([[1,2,3],\n",
        "                          [4,5,6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4wVclKXoDjo",
        "outputId": "395989ae-0c8a-4e9b-fcb9-e7f449461e4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 7, 9])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_2d, dim=0) # dim = 0 -> Column wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qe3hyomoc2J",
        "outputId": "ccb613e2-a878-4ff8-e8cb-13bde4462680"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 6, 15])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_2d, dim=1) # dim = 1 -> Row wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFCV7ktno_OO",
        "outputId": "cc760a52-018c-42d8-bbc0-7d0b3e83b6cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5]],\n",
              "\n",
              "        [[ 6,  7,  8],\n",
              "         [ 9, 10, 11]]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR (3-dimensional)\n",
        "tensor_3d = torch.arange(2 * 2 * 3).view(2, 2, 3)\n",
        "tensor_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n8LmITUug05",
        "outputId": "792d7c33-be13-4797-d331-4cd83a03df49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6,  8, 10],\n",
              "        [12, 14, 16]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, 0)  # dim = 0 -> Summation along th 0th dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zWPa1LBvRgM",
        "outputId": "20b99ec5-c395-4f22-a008-f8ef19cb5a2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 22, 26])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, (0,1)) # firstly summation along the 0th dimension & then along column wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YEgOphuvv_5",
        "outputId": "feed51b1-9911-429b-bbb6-d432c5608084"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([24, 42])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, (0,2))  # firstly summation along the 0th dimension & then along row wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5MokjMCvsX7",
        "outputId": "e90eb4e7-079c-4fa6-ba45-db58f22fe71f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5]],\n",
              "\n",
              "        [[ 6,  7,  8],\n",
              "         [ 9, 10, 11]]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR (3-dimensional)\n",
        "tensor_3d = torch.arange(2 * 2 * 3).view(2, 2, 3)\n",
        "tensor_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsdvTNdTuJfd",
        "outputId": "13d5ac84-b1d9-4333-92fe-b9052a06765d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 3,  5,  7],\n",
              "        [15, 17, 19]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, 1)  # dim = 1 -> Column wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHwEPa9avZo1",
        "outputId": "c4e780b6-f3b6-448b-f21b-6061263f7632"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 22, 26])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, (1,0))  # firstly Column wise summation & then Column wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM-1r37cvihC",
        "outputId": "ec466167-78b6-48e0-9d4e-ec0ba60509db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15, 51])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, (1,2)) # firstly Column wise summation   & then Row wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67U131bKwxju",
        "outputId": "0f79b291-616f-4b9b-f641-c5ade32ffb17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5]],\n",
              "\n",
              "        [[ 6,  7,  8],\n",
              "         [ 9, 10, 11]]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR (3-dimensional)\n",
        "tensor_3d = torch.arange(2 * 2 * 3).view(2, 2, 3)\n",
        "tensor_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HsNNQ0gpAIj",
        "outputId": "5d4e0e58-19e7-4b46-ef0d-98563b1d4ecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 3, 12],\n",
              "        [21, 30]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, 2)  # dim = 2 -> Row wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YVvWsUBswoA",
        "outputId": "0ba8cd9b-8c10-409b-8f9a-9777985dc6f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([24, 42])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, (2,0)) # firstly Row wise summation   & then Column wise summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzmb_8TNps4C",
        "outputId": "31d296a5-3490-4e93-d798-5b713d861314"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15, 51])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(tensor_3d, (2,1)) # firstly Row wise summation   & then Row wise summation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyCAdlo6x-je"
      },
      "source": [
        "### 3.3 Matrix Multiplication\n",
        "\n",
        "\n",
        "\n",
        " [Matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html) is the most common operation in machine learing and deep learning.\n",
        "\n",
        "> **Note:** A matrix multiplication is also refered as [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) of two matrices.\n",
        "\n",
        "\n",
        "In the PyTorch, we can use [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method to impliment the matrix multiplication functionality.\n",
        "\n",
        ">Matrix Multiplication rule must fulfil:                   \n",
        " The **inner dimensions** must match:\n",
        "  * `(4, 3) @ (4, 3)` won't work\n",
        "  * `(2, 4) @ (4, 2)` will work\n",
        "  * `(3, 2) @ (2, 3)` will work\n",
        "\n",
        ">The resulting matrix will have the shape of the **outer dimensions**:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Note:** \"`@`\" in Python is the symbol for matrix multiplication.\n",
        "\n",
        "> **Resource:** Here is the comple guide for matrix multiplication using `torch.matmul()` [in the PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zN-BQtk9e18",
        "outputId": "23ef5108-7afc-410a-9f55-0496b78d5f31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7psIMPIK5OiX"
      },
      "source": [
        "*The difference between element-wise multiplication and matrix multiplication is the addition of values*.\n",
        "\n",
        "> Element-wise multiplication involves multiplying corresponding elements of two matrices, resulting in a new matrix with the same dimensions.\n",
        "\n",
        "> Matrix multiplication is a new matrix, where each element is obtained by taking the sum of the products of corresponding elements.\n",
        "\n",
        "\n",
        "\n",
        " Below is the representation of the how both work for a `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lbckaoC3yI1",
        "outputId": "c2592d30-c823-40f6-fef9-e892113e4fbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Elemet wise multiplication of two tensors\n",
        "tensor * tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlACcy096dz",
        "outputId": "6fb6e294-22e3-42f1-f583-dca4e5f281bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix Multiplication\n",
        "torch.matmul(tensor,tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqu9g8MN-WZY",
        "outputId": "5a8f17e6-20d0-4278-8441-c45755f47a2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @ can be used for the matmul , but not recomended\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Us6k7J-69A"
      },
      "source": [
        "We can face the error `shape mismatch` during matrix multiplication.\n",
        "\n",
        "Matrix multiplication matrices have a strict rule about what shapes and sizes can be combined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "_iFsWUQp_fRF",
        "outputId": "d3b05e6d-6cc4-4156-d3b9-2f7849eb8383"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-aceec990e652>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                          [9, 12]], dtype=torch.float32)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC5BG7hZBDsG"
      },
      "source": [
        "Now we will do the matrix multplication between  `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
        "\n",
        "**Transpose** can switch the dimensions of the tensors.\n",
        "\n",
        "You can perform transposes in PyTorch using either:\n",
        "* [`torch.transpose(input, dim0, dim1)`](https://pytorch.org/docs/stable/generated/torch.transpose.html) - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "* [`tensor.T`](https://pytorch.org/docs/stable/generated/torch.t.html) - where `tensor` is the desired tensor to transpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvZnpBwtCacZ",
        "outputId": "f3084893-ff6b-4451-b84f-d43b3acf812e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# tensor beofre transpose\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTfpgw1IC1H5",
        "outputId": "2c820c4f-af41-4c34-d552-51136fd43c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ],
      "source": [
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8Wo3yY-Dyqv",
        "outputId": "f40b08b9-8e07-4ced-cf10-7ed3e4476678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]),                 tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes:      tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Matrix Multiplication: torch.Size([3, 2]) * torch.Size([2, 3]) <- Here the inner dimensions match\n",
            "\n",
            "Mtrix Multiplication OutPut:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape},                 tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes:      tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Matrix Multiplication: {tensor_A.shape} * {tensor_B.T.shape} <- Here the inner dimensions match\\n\")\n",
        "print(\"Mtrix Multiplication OutPut:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGIQJ81xD97E"
      },
      "source": [
        "We can also use [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) which is a alias for `torch.matmul()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WNrei65EpSm",
        "outputId": "b0119f9f-64d8-4f72-896f-b8c37e732898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mm(tensor_A,tensor_B.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C6KNwjiE3Xm"
      },
      "source": [
        "How the Matrix Multiplication look like ?\n",
        "\n",
        "![Visual Demo](https://github.com/mhamzaraheel/pytorch_DeepLearning/blob/main/Images/1%23-matrix-multiply.gif?raw=true)\n",
        "\n",
        " Matrix Multiplication Visualzation - http://matrixmultiplication.xyz.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHp6YO3SGb1O"
      },
      "source": [
        "## 4.Min, Max and Mean (Aggregation)\n",
        " **Resource** = we can find the min, max and mean by using the  > [`torch.min()`](https://pytorch.org/docs/stable/generated/torch.min.html) ,\n",
        "[`torh.max()`](https://pytorch.org/docs/stable/generated/torch.min.html) ,\n",
        "[`torch.mean()`](https://pytorch.org/docs/stable/generated/torch.mean.html) respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5RaC1LDKgih",
        "outputId": "677d848a-cede-4686-dc96-679847c77bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_tensor = torch.arange(0,10,1)\n",
        "x_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JsSpzxfKwI2",
        "outputId": "a21a12ac-9a5b-4792-f4c2-c7480f03aa74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  tensor(0)\n",
            "Min:  tensor(9)\n",
            "Min:  tensor(4.5000)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Min: \",x_tensor.min())\n",
        "print(f\"Min: \",x_tensor.max())\n",
        "print(f\"Min: \",x_tensor.type(torch.float).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuvlhJUGN1fs"
      },
      "source": [
        "**Note:** We get the error as `torch.mean()` require tensors to be in `torch.float` or `torch.Long` . So we firslt\n",
        "\n",
        "You can also do the same as above with `torch` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcGPy7YvOw_d",
        "outputId": "90c72df0-9db2-4077-a254-a4bd4cd200b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0), tensor(9), tensor(4.5000))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.min(x_tensor) , torch.max(x_tensor) , torch.mean(x_tensor.type(torch.float))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZAlEkAFOVlF"
      },
      "source": [
        "We can also find the min mix and mean along the dimensions (See the Documentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmkmHvUePFEP"
      },
      "source": [
        "## 5.Positional min/max\n",
        "\n",
        "Some time we need to find the index where the min and max occurs we can find it as  [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x--70XXPhwN",
        "outputId": "cecd14f8-134c-4787-8ce7-8ef35ca7147e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index of min value: 0\n",
            "Index of max value: 8\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index of min value: {tensor.argmin()}\")\n",
        "print(f\"Index of max value: {tensor.argmax()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5TSimRGQDJ0"
      },
      "source": [
        "## 6.Reshaping, Stacking, Squeezing and Unsqueezing\n",
        "\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "\n",
        "\n",
        "[`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) > Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`.\n",
        "\n",
        "[`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) > Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "[`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) > Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size.\n",
        "\n",
        "[`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) > Squeezes `input` to remove all the dimenions with value `1`(removes all 1 dimensions from a tensor).\n",
        "\n",
        "[`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) >  Returns `input` with a dimension value of `1` added at `dim`(add a 1 dimension to a target tensor).\n",
        "\n",
        "[`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) > Returns a *view* of the original `input` with its dimensions permuted (swapped) to `dims`.\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "*To get rid of shape misamtch errors.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EatLE1IaZYr4"
      },
      "source": [
        "> Reshape the tensor into new shape `torch.reshape()`.\n",
        "For Better understadig see the documentation and practice all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gytk8oMsQuFg",
        "outputId": "11a1ff21-55d5-44b3-d727-4c6b8b81940e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creat the tensor\n",
        "x = torch.arange(1,11)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZpjf1JNU6mJ",
        "outputId": "6a4bf513-8a9b-40f6-c560-bc1885f56711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reshape the tensor\n",
        "x.reshape(2,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPrjq-LPVOlr",
        "outputId": "53547931-68b3-450c-ab78-86b2d0f85d85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Same as above\n",
        "torch.reshape(x,(2,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-jFATu7VTy6"
      },
      "source": [
        "> We can also change the view with `torch.view()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTnuCC49WBaR",
        "outputId": "6244fac0-fb74-483d-9ba0-f161f750c82b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.view(2,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8RSPGUyW5U5"
      },
      "source": [
        "> If we want to stack different tensors, we could do so with `torch.stack()` \"Size must same\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0xTSkrrYyiF",
        "outputId": "e8197622-e263-4083-c4fa-799452fbb466"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "torch.stack([x,x,x], dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lWvuwPSYdYn",
        "outputId": "97cb2e7b-27f4-4d80-ac2c-4f4145188106"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  1,  1],\n",
              "        [ 2,  2,  2],\n",
              "        [ 3,  3,  3],\n",
              "        [ 4,  4,  4],\n",
              "        [ 5,  5,  5],\n",
              "        [ 6,  6,  6],\n",
              "        [ 7,  7,  7],\n",
              "        [ 8,  8,  8],\n",
              "        [ 9,  9,  9],\n",
              "        [10, 10, 10]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "torch.stack([x,x,x], dim = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BHiEQm9YjpC"
      },
      "source": [
        "\n",
        ">Can remove all single dimensions from a tensor?\n",
        "To do so you can use `torch.squeeze()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ0aJSuRZwyw",
        "outputId": "aa599dd7-8cfa-4a59-f4ed-83d1a28e41fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]), torch.Size([1, 10]))"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  Before squeezing\n",
        "reshaped_tensor = x.reshape(1,10)\n",
        "reshaped_tensor , reshaped_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTX9aAsxaAkH",
        "outputId": "1f0e0340-22ed-4de9-9dca-16999430f1bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), torch.Size([10]))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# after squeezing, remove the 1-dim\n",
        "reshaped_tensor.squeeze() , reshaped_tensor.squeeze().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE2cO-UEabnQ"
      },
      "source": [
        "> You can also use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQGxoQDKcjt_",
        "outputId": "fcf75d0d-681e-4352-8a1f-2706e72d9c0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]), torch.Size([1, 10]))"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reshaped_tensor,reshaped_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbrV6bwlcgYL",
        "outputId": "28d7e61f-567f-4005-ed46-c8fb13a326d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]]), torch.Size([1, 1, 10]))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra dimension with unsqueeze\n",
        "reshaped_tensor.unsqueeze(dim=0) , reshaped_tensor.unsqueeze(dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3LOxReJawo0",
        "outputId": "8f429d7d-a8fa-44df-c945-fbb7ded0845f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 1],\n",
              "          [ 2],\n",
              "          [ 3],\n",
              "          [ 4],\n",
              "          [ 5],\n",
              "          [ 6],\n",
              "          [ 7],\n",
              "          [ 8],\n",
              "          [ 9],\n",
              "          [10]]]),\n",
              " torch.Size([1, 10, 1]))"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra dimension with unsqueeze\n",
        "reshaped_tensor.unsqueeze(dim=2) , reshaped_tensor.unsqueeze(dim=2).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FzwDwkMb24b"
      },
      "source": [
        ">  You can also swap the order of axes values with `torch.permute(input, dims)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SswzXrOHc9Ql",
        "outputId": "d2ecf787-5560-40a8-fe48-726ecc48e37e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 28, 28])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# original tensor\n",
        "some_tensor = torch.rand(3,28,28)\n",
        "some_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JZPXyr2dZMR",
        "outputId": "4985781d-2fcd-460d-fe86-d0b933dce269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([28, 3, 28])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "some_tensor.permute(2,0,1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Woyk7UgFdiP8"
      },
      "source": [
        "## 7.Indexing (selecting specific data from tensors)\n",
        "\n",
        "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        "Indexing can help here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fePlEdKugzP-",
        "outputId": "b3554c8e-9f45-4360-b403-dd1d903ccb41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3,  4,  5],\n",
              "         [ 6,  7,  8,  9, 10],\n",
              "         [11, 12, 13, 14, 15]]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(1,16).reshape (1,3,5)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZAxH0kLhFpV",
        "outputId": "743e3e1c-2973-47af-b24e-790bab7adea4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10],\n",
              "        [11, 12, 13, 14, 15]])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the 0th index of 0th dimension\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S73pK5Gkhkcs",
        "outputId": "b2220b69-1c6f-4201-c951-067bc8358cb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5]), tensor([1, 2, 3, 4, 5]))"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the 0th index of 1st dimension\n",
        "x[0][0],x[0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4AJkEPLhuPj",
        "outputId": "6e46469f-a229-4281-a11c-3dbe10f043f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the 0th index of 2nd dimension\n",
        "x[0][0][0], x[0,0,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUdNu2nBhvKT"
      },
      "source": [
        "We can also use `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMtBTplGiGec",
        "outputId": "cac15899-798d-4e7f-b3f8-ff29f68eb85c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, 12, 13, 14, 15]])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all values of the 0th dimension and 3rd index of 1st dimension\n",
        "x[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDn6xIlfiKuW",
        "outputId": "a253627d-1dc9-4d1c-97d0-0d29eb86c757"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2,  7, 12]])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all the values of 0th dimension & first dimension , and 2nd index of 3rd dimension\n",
        "x[:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPKXK4Wdji-s",
        "outputId": "c525b4f0-5b03-4f29-8828-37f0ba113129"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItwYlrV7jsEx"
      },
      "source": [
        "## 8.PyTorch Tensors & NumPy Arrays\n",
        "\n",
        "Sometimes we need to swap between the numpy and  pytorch.\n",
        "\n",
        "The two main methods we'll  use for NumPy to PyTorch (and vice vers) are:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZCSsxvYkr7Q",
        "outputId": "b83b4567-481b-4220-c936-b657a9c6a382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "array  = np.arange(1,10)\n",
        "array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMVU3sb0lJ32",
        "outputId": "3ef20e22-d61b-403c-cd22-04967cfd1379"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Numpy array to torch tensor\n",
        "tensor = torch.from_numpy(array)\n",
        "tensor , array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFd3e4DlQfF"
      },
      "source": [
        "If we change the tensor , there will be no effect in the array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goXSEBT1le_c",
        "outputId": "5559c687-415e-44d1-cf4c-048a76de7a53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Torch tensor to numpy array\n",
        "array = tensor.numpy()\n",
        "array , tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEkAHmM3mP0H"
      },
      "source": [
        "## 9.Reproducibilty (`torch.manual_seed(seed)`)\n",
        "\n",
        "\n",
        "Although random numbers(randomness) is nice and powerful, sometimes you'd like there to be generate the same random number in each time you run the code (little_less_randomness).\n",
        "\n",
        "*Why we need litle_less_randomness?*\n",
        "\n",
        "So we can perform repeatable experiments on the same Radom numbers(randomness).\n",
        "\n",
        "For example, you have created  an algorithm capable of achieving some X data performance. And then your friend tries to verify it.                                       \n",
        " *How could you do such a thing?*\n",
        "\n",
        "That's where **reproducibility** comes in.\n",
        "\n",
        "In other words, we can you get the same (or very similar) results on different computer.\n",
        "\n",
        "\n",
        "**Resource:** Here is the [The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA7cm4OWnSIr",
        "outputId": "1a5d5d14-8d4c-4372-ebfb-7d606204b750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2391, 0.7399, 0.8463],\n",
            "        [0.3826, 0.7392, 0.1296],\n",
            "        [0.1648, 0.2451, 0.5992]])\n",
            "\n",
            "\n",
            "tensor([[0.7277, 0.1344, 0.0548],\n",
            "        [0.6459, 0.0130, 0.4335],\n",
            "        [0.2083, 0.3876, 0.3694]])\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False]])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creat the two random tensors\n",
        "tensor_x = torch.rand(3,3)\n",
        "tensor_y = torch.rand(3,3)\n",
        "\n",
        "print(tensor_x)\n",
        "print(\"\\n\")\n",
        "print(tensor_y)\n",
        "# Now check if they are equal or not\n",
        "print(\"\\n\")\n",
        "tensor_x == tensor_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMfcoY5oQbL"
      },
      "source": [
        "As you can see above , both the tensors are of different values.\n",
        "\n",
        "How if you want to generate the two random tesor having the *same* value.\n",
        "\n",
        "That's where [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer (like `42` but it could be anything) that flavours the randomness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE4nGM--o-9x",
        "outputId": "afd5d2fd-cd27-4217-e5bc-5f9b4131c396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009],\n",
            "        [0.2566, 0.7936, 0.9408]]) \n",
            "\n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009],\n",
            "        [0.2566, 0.7936, 0.9408]])\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(seed = RANDOM_SEED)\n",
        "\n",
        "tensor_A = torch.rand(3,3)\n",
        "print(tensor_A,\"\\n\")\n",
        "\n",
        "torch.manual_seed(seed = RANDOM_SEED) # without this second tensor will be diffrent fron one.\n",
        "\n",
        "tensor_B= torch.rand(3,3)\n",
        "print(tensor_B)\n",
        "\n",
        "\n",
        "# check if they both are equal or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpw1NFCitBoe"
      },
      "source": [
        "## 10.Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "GPUs are crucial in deep learning for parallel processing, accelerating complex operations and reducing training time. Their high memory bandwidth efficiently handles large datasets, making them essential for neural network computations and overall model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqOW6EgzqTFT",
        "outputId": "222b788c-2979-4440-866c-e539d2c3983b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OVZ0j6ptBOV"
      },
      "source": [
        "\n",
        "\n",
        "### 10.1 Getting PyTorch to run on the GPU\n",
        "\n",
        "Once you've got a GPU ready to access, the next step getting pytorch so that we can use the gpu for processing.\n",
        "\n",
        "To do so, you can use the [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) package.\n",
        "\n",
        "You can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYVt37rnujgA",
        "outputId": "0c748332-1ce5-4581-b2d5-a91d6de075e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for GPU\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bb0p4JhuxAU"
      },
      "source": [
        "As you can see that if the output is False , it mean GPU is not available.\n",
        "\n",
        "To make that our code run on CPU or GPU if it is available , we have a setup.\n",
        "\n",
        "That's why , somene run the code , regardless of computing device they are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X5FboI4E3bxU",
        "outputId": "652463ba-dace-4aab-8156-1ec301ab4677"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# it is the device agnostic code.\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMq5ibUQ4AO2"
      },
      "source": [
        "If we get the `cuda` then we can process by setting our code to available `CUDA` device, other wise it will go with the CPU.  \n",
        "\n",
        "> **Note:** In PyTorch, it's best practice to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "For more better Performance you can use multiple GPU.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn8NhCcK5Csk",
        "outputId": "53be5b04-0c05-4051-f006-d6360c20c487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M__XbmJv5Haz"
      },
      "source": [
        "### 10.2 Putting tensors (and models) on the GPU\n",
        "\n",
        "You can put tensors and models on a specific device by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the target device you'd like the tensor (or model) to go to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jlo8KXb5uhM",
        "outputId": "7f40134a-f713-4f3b-bac8-6698fe2c9925"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cpu_tensor = torch.tensor([1,2,3])\n",
        "cpu_tensor, some_tensor.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9SRtAo850lk",
        "outputId": "dc547818-d20c-45a7-a6f2-c405247f67ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_tensor = cpu_tensor.to(device)   #it will convert into gpu , if it is available\n",
        "gpu_tensor , gpu_tensor.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qp_v3fN6ENF"
      },
      "source": [
        "### 10.3 Moving tensors back to the CPU\n",
        "\n",
        "\n",
        "Some time we need to move the tensor back to cpu, *How can we do this?*\n",
        "\n",
        "\n",
        "For example, NumPy does not leverage the GPU.\n",
        "\n",
        "Let's try using the [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li727HdN64c0",
        "outputId": "8ec7e930-d655-4543-ca67-86d97f620689"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_tensor.numpy()    # it will give the error if the gpu_tesor is on gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSEJPaNs7KXX",
        "outputId": "6a5ad12c-ddea-47b0-a3ce-28b5730d16c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_tensor.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36TGgdGO7Nao",
        "outputId": "9ef1d24c-09ea-465e-b4df-85b8de50cb89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = gpu_tensor.cpu()\n",
        "tensor_back_on_cpu.device"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
